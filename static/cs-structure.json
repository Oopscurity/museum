{
  "data": {
    "title": "Информатика",
    "description": "![Computer science](https://upload.wikimedia.org/wikipedia/commons/3/39/Lambda_lc.svg)\n\n**Информатика** - Наука о методах и процессах сбора, хранения, обработки, передачи, анализа и оценки информации с применением компьютерных технологий, обеспечивающих возможность её использования для принятия решений."
  },
  "children": [
    {
      "data": {
        "title": "Кибернетика",
        "description": ""
      },
      "children": [
        {
          "data": {
            "title": "Бионика",
            "description": ""
          },
          "children": []
        },
        {
          "data": {
            "title": "Гомеостатика",
            "description": ""
          },
          "children": []
        },
        {
          "data": {
            "title": "Распознавание образов",
            "description": ""
          },
          "children": []
        },
        {
          "data": {
            "title": "Автоматическое управление",
            "description": ""
          },
          "children": []
        },
        {
          "data": {
            "title": "Математическая лингвистика",
            "description": ""
          },
          "children": []
        }
      ]
    },
    {
      "data": {
        "title": "Теоретическая информатика",
        "description": ""
      },
      "children": [
        {
          "data": {
            "title": "Математическая логика"
          },
          "children": [
            {
              "data": {
                "title": "Годфрид Вильгельм Лейбниц",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/commons/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg)\n\nВ области логики Годфрид Вильгельм Лейбниц разрабатывал учение об анализе и синтезе. Логику он понимал как науку о всех возможных мирах. Лейбницу принадлежит первая в истории формулировка закона достаточного основания; он также является автором принятой в современной логике формы выражения закона тождества. Закон тождества он считал высшим принципом логики. «Природа истины вообще состоит в том, что она есть нечто тождественное».\n\nСформулированный Лейбницем закон тождества в настоящее время используется в большинстве современных логико-математических исчислений. С законом тождества связан принцип подстановки эквивалентных: «Если А есть В и В есть А, тогда А и В называются „тем же самым“. Или: А и В есть то же самое, если они могут быть подставлены один вместо другого».\n\nЕдиной системы обозначений Лейбниц не выработал, наиболее разработано им исчисление «плюс — минус». Удачным оказалось предложенное Лейбницем для вывода правильных модусов силлогизмов представление суждений посредством параллельных отрезков или кругов.\n\nЛейбниц выступил создателем наиболее полной для его времени классификации определений, кроме того, он разработал теорию генетических определений. В своём труде «Об искусстве комбинаторики», написанном в 1666 году, Лейбниц предвосхитил некоторые моменты современной математической логики. \n\nГотфриду Вильгельму Лейбницу принадлежит авторство идеи использования математической символики в логике и построений логических исчислений. Он выдвинул задачу фундирования математических истин на общелогических принципах, а также предложил применить бинарную, то есть двоичную, систему счисления для целей вычислительной математики. Лейбниц обосновал значение рациональной символики для логики и для эвристических заключений; он утверждал, что познание сводится к доказательствам утверждений, находить же доказательства необходимо по определённому методу. Согласно Лейбницу, сам по себе математический метод не достаточен, чтобы открыть всё то, что мы ищем, но он предохраняет от ошибок.\n\nВ «Новых опытах» (книга 4) Лейбниц дал дедуктивный анализ традиционной логики, показав, что 2-я и 3-я фигуры силлогизма могут быть получены как следствие из модуса Barbara при помощи закона противоречия, а 4-я фигура — с использованием закона обращения; здесь же он дал новую классификацию модусов силлогизма."
              }
            },
            {
              "data": {
                "title": "Джордж Буль",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/commons/6/6c/George_Boole.jpg)\n\nБуль был, вероятно, первым после Джона Валлиса математиком, обратившимся к логической проблематике. Идеи применения символического метода к логике впервые высказаны им в статье «Математический анализ логики» (1847). Не удовлетворённый полученными в ней результатами, Буль высказывал пожелание, чтобы о его взглядах судили по обширному трактату «Исследование законов мышления, на которых основываются математические теории логики и вероятностей» (1854). Буль не считал логику разделом математики, но находил глубокую аналогию между символическим методом алгебры и символическим методом представления логических форм и силлогизмов. Единицей Буль обозначал универсум мыслимых объектов, буквенными символами — выборки из него, связанные с обычными прилагательными и существительными (так, если x = \"рогатые\", а y = \"овцы\", последовательный выбор x и y из единицы даст класс рогатых овец). Буль показал, что символика такого рода подчиняется тем же законам, что и алгебраическая, из чего следовало, что их можно складывать, вычитать, умножать и даже делить. В такой символике высказывания могут быть сведены к форме уравнений, а заключение из двух посылок силлогизма — получено путём исключения среднего термина по обычным алгебраическим правилам. Ещё более оригинальной и примечательной была часть его системы, представленной в «Законах мышления…», образующая общий символический метод логического вывода. Буль показал, как из любого числа высказываний, включающих любое число терминов, вывести любое заключение, следующее из этих высказываний, путём чисто символических манипуляций. Вторая часть «Законов мышления…» содержит аналогичную попытку обнаружить общий метод в исчислении вероятностей, позволяющий из заданных вероятностей совокупности событий определить вероятность любого другого события, логически связанного с ними."
              }
            },
            {
              "data": {
                "title": "Фридрих Людвиг Готлоб Фреге",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/commons/9/99/Young_frege.jpg)\n\nВклад Фреге в логику многие сравнивают с вкладом Аристотеля, Курта Гёделя и Альфреда Тарского. Его революционное сочинение Begriffsschrift (Исчисление понятий) (1879) положило начало новой эпохе в истории логики. В Begriffsschrift Фреге с совершенно новых позиций пересмотрел ряд математических проблем, включая ясную трактовку понятий функции и переменных. Он, по сути дела, изобрел и аксиоматизировал логику предикатов, благодаря своему открытию кванторов, использование которых постепенно распространилось на всю математику и позволило решить средневековую проблему множественной общности. Эти достижения открыли дорогу к теории описаний Бертрана Рассела и Principia Mathematica (написанной Расселом вместе с Альфредом Уайтхедом), и знаменитой гёделевской теореме о неполноте.\n\nФреге ввел различение между смыслом (нем. Sinn) и значением (нем. Bedeutung) понятия, обозначаемого определенным именем (так называемый треугольник Фреге или семантический треугольник: знак—смысл—значение). Под значением в рамках его системы представлений понималась предметная область, соотнесенная с неким именем. Под смыслом подразумевается определенный аспект рассмотрения этой предметной области."
              }
            }
          ]
        },
        {
          "data": {
            "title": "Вычислительная математика",
            "description": ""
          },
          "children": [
            {
              "data": {
                "title": "Брук Тейлор",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/commons/2/25/BTaylor.jpg)\n\n**Ряд Тейлора** — разложение функции в бесконечную сумму степенных функций.\n\nРядом Тейлора функции ![enter image description here](https://wikimedia.org/api/rest_v1/media/math/render/svg/202945cce41ecebb6f643f31d119c514bec7a074), бесконечно дифференцируемой в точке ***a***, называется функциональный формальный ряд\n\n![enter image description here](https://wikimedia.org/api/rest_v1/media/math/render/svg/9590b3a377cd134e79724beec5abfc59ac643c42) с параметром ***a***\n\nТо есть, рядом Тейлора для функции ![enter image description here](https://wikimedia.org/api/rest_v1/media/math/render/svg/202945cce41ecebb6f643f31d119c514bec7a074) в окрестности точки ***a*** называется степенной ряд относительно двучлена ![enter image description here](https://wikimedia.org/api/rest_v1/media/math/render/svg/e32f42f9f52615f0186e3c8f2c25d7cd6f7bd6aa) вида \n\n![enter image description here](https://wikimedia.org/api/rest_v1/media/math/render/svg/59ccf0743594b31adcee108369960f7534a7b431)\n\nТеорема Тейлора даёт приближение к функции, дифференцируемой k раз, вблизи данной точки с помощью многочлена Тейлора k-го порядка. Для аналитических функций многочлен Тейлора в данной точке является частичной суммой их ряда Тейлора, который, в свою очередь, полностью определяет функцию в некоторой окрестности точки. Точное содержание теоремы Тейлора до настоящего времени не согласовано. Конечно, существует несколько версий теоремы, применимых в различных ситуациях, и некоторые из этих версий содержат оценки ошибки, возникающей при приближении функции с помощью многочлена Тейлора.\n\nЭта теорема названа в честь математика Брука Тейлора, который сформулировал одну из её версий в 1712 году. Явное выражение для ошибки приближения было дано намного позже Жозефом Лагранжем. Ранее, в 1671 году, Джеймсом Грегори уже было упомянуто следствие из теоремы.\n\nТеорема Тейлора позволяет овладеть приёмами вычислений начального уровня, и она является одним из центральных элементарных инструментов в математическом анализе. При изучении математики она является начальной точкой для изучения асимптотического анализа (англ.). Теорема также используется в математической физике. Она также обобщается на функции нескольких переменных и векторные функции f : Rn → Rm для любых размерностей n и m. Это обобщение теоремы Тейлора является базовым для определения так называемых струй, которые появляются в дифференциальной геометрии и в теории дифференциальных уравнений с частными производными."

              }
            },
            {
              "data": {
                "title": "Пафнутий Львович Чебышёв",
                "description": "Основные математические исследования П. Л. Чебышёва относятся к теории чисел, теории вероятностей, теории приближения функций, математическому анализу, геометрии, прикладной математике.\n\n\n\nТворческий метод Чебышёва отличало стремление к увязке проблем математики с вопросами естествознания и техники и к соединению абстрактной теории с практикой. Учёный указывал: «Сближение теории с практикою даёт самые благотворные результаты, и не одна только практика от этого выигрывает: сами науки развиваются под влиянием её: она открывает им новые предметы для исследования или новые стороны в предметах давно известных… Если теория много выигрывает от новых приложений старой методы или от новых развитий её, то она ещё более приобретает открытием новых метод, и в этом случае науки находят себе верного руководителя в практике».\n\nТеория чисел.\n\nИз многочисленных открытий Чебышёва надо упомянуть прежде всего работы по теории чисел. Начало им было положено докторской диссертацией Чебышёва «Теория сравнений», напечатанной в 1849 году; она стала первой отечественной монографией по теории чисел. Этот труд несколько раз переиздавался, был переведен на немецкий и итальянский языки.\n\nТеория вероятностей.\n\nЧебышёв стал первым русским математиком мирового уровня и в теории вероятностей. С 1860 года он сменил В. Я. Буняковского на кафедре теории вероятностей Петербургского университета и начал свой цикл лекций. Он опубликовал по данной теме всего четыре работы, но фундаментального характера. В статье «О средних величинах» (1866 год) было впервые доказано «неравенство Чебышёва», позднее усиленное Марковым.\n\nТеория приближенной функции.\n\nХотя теория приближения функций имеет достаточно богатую предысторию, собственно историю этого раздела математики принято исчислять с 1854 года, когда была опубликована статья П. Л. Чебышёва «Теория механизмов, известных под названием параллелограммов». Она стала первой из серии работ учёного по «функциям, наименее уклоняющимся от нуля» (исследованиям в данной области Чебышёв посвятил сорок лет)."
              }
            }
          ]
        },
        {
          "data": {
            "title": "Теория информатики",
            "description": ""
          },
          "children": [
            {
              "data": {
                "title": "Дэвид Хаффман",
                "desctiption": "![enter image description here](http://www.adeptis.ru/vinci/david_huffman1.jpg)\n\nАлгоритм Хаффмана — жадный алгоритм оптимального префиксного кодирования алфавита с минимальной избыточностью. Был разработан в 1952 году аспирантом Массачусетского технологического института Дэвидом Хаффманом при написании им курсовой работы. В настоящее время используется во многих программах сжатия данных.\n\nЭтот метод кодирования состоит из двух основных этапов:\n\n   1. Построение оптимального кодового дерева; \n\n  2. Построение отображения код-символов на основе построенного дерева.\n\n Один из первых алгоритмов эффективного кодирования информации был предложен Д. А. Хаффманом в 1952 году. Идея алгоритма состоит в следующем: зная вероятности символов в сообщении, можно описать процедуру построения кодов переменной длины, состоящих из целого количества битов. Символам с большей вероятностью ставятся в соответствие более короткие коды. Коды Хаффмана обладают свойством префиксности (то есть ни одно кодовое слово не является префиксом другого), что позволяет однозначно их декодировать.\n\nКлассический алгоритм Хаффмана на входе получает таблицу частот встречаемости символов в сообщении. Далее на основании этой таблицы строится дерево кодирования Хаффмана (Н-дерево).\n\n 1. Символы входного алфавита образуют список свободных узлов. Каждый лист имеет вес, который может быть равен либо вероятности, либо количеству вхождений символа в сжимаемое сообщение\n\n 2.  Выбираются два свободных узла дерева с наименьшими весами.\n\n 3. Создается их родитель с весом, равным их суммарному весу.\n\n 4. Родитель добавляется в список свободных узлов, а два его потомка удаляются из этого списка.\n\n 5. Одной дуге, выходящей из родителя, ставится в соответствие бит 1, другой — бит 0.\n\n 6.  Шаги, начиная со второго, повторяются до тех пор, пока в списке свободных узлов не останется только один свободный узел. Он и будет считаться корнем дерева."
              }
            },
            {
              "data": {
                "title": "Клод Шеннон",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/ru/3/3d/Shannon.jpg)\n\nКлод Элвуд Шеннон (англ. Claude Elwood Shannon; 30 апреля 1916, Петоцки (англ.)русск., Мичиган, США — 24 февраля 2001, Медфорд, Массачусетс, США) — американский инженер и математик, его работы являются синтезом математических идей с конкретным анализом чрезвычайно сложных проблем их технической реализации.\n\nЯвляется основателем теории информации, нашедшей применение в современных высокотехнологических системах связи. Шеннон внес огромный вклад в теорию вероятностных схем, теорию автоматов и теорию систем управления — области наук, входящие в понятие «кибернетика». В 1948 году предложил использовать слово «бит» для обозначения наименьшей единицы информации (в статье «Математическая теория связи»).\n\nАлгоритм Шеннона — Фано — один из первых алгоритмов сжатия, который впервые сформулировали американские учёные Шеннон и Роберт Фано. Данный метод сжатия имеет большое сходство с алгоритмом Хаффмана, который появился на несколько лет позже и является логическим продолжением алгоритма Шеннона. Алгоритм использует коды переменной длины: часто встречающийся символ кодируется кодом меньшей длины, редко встречающийся — кодом большей длины. Коды Шеннона — Фано префиксные, то есть никакое кодовое слово не является префиксом любого другого. Это свойство позволяет однозначно декодировать любую последовательность кодовых слов.Кодирование Шеннона — Фано (англ. Shannon–Fano coding) — алгоритм префиксного неоднородного кодирования. Относится к вероятностным методам сжатия (точнее, методам контекстного моделирования нулевого порядка). Подобно алгоритму Хаффмана, алгоритм Шеннона — Фано использует избыточность сообщения, заключённую в неоднородном распределении частот символов его (первичного) алфавита, то есть заменяет коды более частых символов короткими двоичными последовательностями, а коды более редких символов — более длинными двоичными последовательностями.\n\nАлгоритм был независимо друг от друга разработан Шенноном (публикация «Математическая теория связи», 1948 год) и, позже, Фано (опубликовано как технический отчёт).\n\nОсновные этапы:\n\n1. Символы первичного алфавита m1 выписывают по убыванию вероятностей.\n\n2. Символы полученного алфавита делят на две части, суммарные\n\n    вероятности символов которых максимально близки друг другу. \n\n3. В префиксном коде для первой части алфавита присваивается двоичная цифра «0», второй части — «1». \n\n4. Полученные части рекурсивно делятся и их частям назначаются соответствующие двоичные цифры в префиксном коде."
              }
            },
            {
              "data": {
                "title": "Роберт Фано",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/commons/1/11/Robert_Fano_2012-03-13.jpg)\n\nРоберт Марио Фано (Robert Mario Fano, 11 ноября 1917[2], Турин, Италия — 13 июля 2016, Нейплс, Флорида, США) — итальяно-американский учёный в области информатики, профессор-эмерит факультетов электротехники и компьютерных наук в Массачусетском технологическом институте, действительный член Национальной академии наук США и ряда других национальных академий. Фано известен по работам в области теории информации, он независимо от Клода Шеннона изобрел ранний алгоритм сжатия информации и вывел неравенство Фано.\n\nАлгоритм Шеннона — Фано — один из первых алгоритмов сжатия, который впервые сформулировали американские учёные Шеннон и Роберт Фано. Данный метод сжатия имеет большое сходство с алгоритмом Хаффмана, который появился на несколько лет позже и является логическим продолжением алгоритма Шеннона. Алгоритм использует коды переменной длины: часто встречающийся символ кодируется кодом меньшей длины, редко встречающийся — кодом большей длины. Коды Шеннона — Фано префиксные, то есть никакое кодовое слово не является префиксом любого другого. Это свойство позволяет однозначно декодировать любую последовательность кодовых слов.Кодирование Шеннона — Фано (англ. Shannon–Fano coding) — алгоритм префиксного неоднородного кодирования. Относится к вероятностным методам сжатия (точнее, методам контекстного моделирования нулевого порядка). Подобно алгоритму Хаффмана, алгоритм Шеннона — Фано использует избыточность сообщения, заключённую в неоднородном распределении частот символов его (первичного) алфавита, то есть заменяет коды более частых символов короткими двоичными последовательностями, а коды более редких символов — более длинными двоичными последовательностями.\n\nАлгоритм был независимо друг от друга разработан Шенноном (публикация «Математическая теория связи», 1948 год) и, позже, Фано (опубликовано как технический отчёт).\n\nОсновные этапы:\n\n1. Символы первичного алфавита m1 выписывают по убыванию вероятностей.\n\n2. Символы полученного алфавита делят на две части, суммарные\n\n    вероятности символов которых максимально близки друг другу. \n\n3. В префиксном коде для первой части алфавита присваивается двоичная цифра «0», второй части — «1». \n\n4. Полученные части рекурсивно делятся и их частям назначаются соответствующие двоичные цифры в префиксном коде."
              }
            }
          ]
        },
        {
          "data": {
            "title": "Системный анализ"
          },
          "children": [
            {
              "data": {
                "title": "Никита Николаевич Моисеев",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/commons/8/89/Nikita_Nikolaevich_Moiseyev-01.jpg)\n\nНикита Николаевич Моисеев (10 [23] августа 1917, Москва — 29 февраля 2000, там же) — советский и российский учёный в области общей механики и прикладной математики, академик Академии наук СССР (впоследствии РАН) (1984) и ВАСХНИЛ (впоследствии РАСХН) (1985), почётный член Российской академии естественных наук (РАЕН), член Международной академии астронавтики (Париж), президент Российского отделения «Зелёного креста», президент Российского национального комитета содействия Программе ООН по охране окружающей среды, президент Международного независимого эколого-политологического университета (МНЭПУ) (1993—2000), главный редактор журнала «Экология и жизнь» (1995—2000). Основатель и руководитель целого ряда научных школ. Автор 35 монографий, 10 учебных пособий и более 300 научных и научно-популярных статей. Труды по динамике твёрдого тела с жидкостью, численным методам математической физики, теории оптимизации управления и др.\n\nОсновные направления исследовательской деятельности\n\n 1. теория системного анализа и оптимальных систем;\n 2. прикладная математика и её приложения для решения сложных задач физики и техники;\n 3. теория и методы расчёта систем управления и траекторий космических объектов;\n 4. теория управления (общие вопросы теории и методы расчёта конкретных систем управления космическими объектами) и методы оптимизации, в том числе природопользования;\n 5. модели динамики биосферы и её стабильности при антропогенных воздействиях (в 1983 году были получены количественные оценки возможных последствий ядерной войны, известные как «ядерная зима» и «ядерная ночь»);\n 6. философия естествознания, в том числе методологические проблемы взаимоотношения биосферы и общества и математические модели стабильности биосферы в условиях антропогенных воздействий;\n 7. философские и политологические проблемы общества в условиях переходного периода России[3], процессов самоорганизации (или универсального эволюционизма, по терминологии Н. Н. Моисеева) и необратимости эволюционных процессов;\n 8. педагогические и этические проблемы формирования нового мировоззрения для пересмотра взаимоотношения человека и природы, идей эпохи ноосферы В. И. Вернадского и провозглашение коэволюции человека и биосферы как условия выживания человека на планете.\n\nН. Н. Моисеев — основоположник целого ряда новых направлений в прикладной математике. Его работы посвящены механике и гидродинамике, численным методам в теории оптимального управления, теории иерархических систем, имитационному моделированию, автоматизации проектирования, междисциплинарным исследованиям экологических проблем. В каждой из этих областей Никите Николаевичу принадлежат основополагающие достижения.\n\nНаучные интересы Н. Н. Моисеева были широки и разнообразны. Понимание перспектив развития прикладной математики, вычислительной техники, острая гражданская заинтересованность проблемами страны 50 с лишним лет определяли направления и характер его деятельности. Будучи заместителем директора Вычислительного центра АН СССР (впоследствии — РАН), Н. Н. Моисеев открывал новые области исследований, устанавливал тесные контакты с отраслевыми НИИ и КБ, создавал новые отделы.\n\nНикита Николаевич содействовал созданию Российского общества экологической экономики (РОЭЭ), и выступил с пленарным докладом на открытии его Первой Международной конференции в 1993 году, был членом Совета общества."
              }
            }
          ]
        },
        {
          "data": {
            "title": "Теория принятия решений"
          },
          "children": [
            {
              "data": {
                "title": "Чарльз Фоги",
                "description": "Rete — эффективный алгоритм сопоставления с образцом для продукционных систем, экспертных систем и баз знаний, созданный Чарльзом Форги из Университета Карнеги Меллона. Впервые был описан в рабочем документе 1974 года, затем в докторской диссертации 1979 и в статье 1982 года (см Ссылки). Rete стал основой многих популярных экспертных систем, включая CLIPS, Jess, Drools, BizTalk Rules Engine и Soar.\n\n\n\nПри наивной реализации экспертная система проверяет применимость каждого правила вывода к каждому факту базы знаний, при необходимости выполняет его и переходит к следующему правилу, возвращаясь в начало при исчерпании всех правил. Даже для небольшого набора правил и фактов такой метод работает неприемлемо медленно. Алгоритм Rete обеспечивает более высокую эффективность. При использовании Rete экспертная система строит специальный граф или префиксное дерево, узлам которого соответствуют части условий правил. Путь от корня до листа образует полное условие некоторой продукции. В процессе работы каждый узел хранит список фактов, соответствующих условию. При добавлении или модификации факта он прогоняется по сети, при этом отмечаются узлы, условиям которых данный факт соответствует. При выполнении полного условия правила, когда система достигает листа графа, правило выполняется.\n\nАлгоритм Rete жертвует объёмом памяти ради скорости. В большинстве случаев скорость возрастает на порядки (так как эффективность теоретически не зависит от числа правил в системе). В экспертных системах с большим числом правил классический Rete требует слишком много памяти, но появились новые алгоритмы, в том числе основанные на Rete, ограничивающиеся разумным объёмом памяти.\n\n\n\nАлгоритм Rete содержит обобщение логики функционала, ответственного за связь данных (фактов) и алгоритма (продукций) в системах сопоставления с образцом (вид систем: системы основанные на правилах). Продукция состоит из одного или нескольких условий и набора действий, выполняемых если актуальный набор фактов соответствует одному из условий. Условия накладываются на атрибуты фактов, включая их типы и идентификаторы. Алгоритм Rete имеет следующие характеристики:\n\n  1. Уменьшает или исключает избыточность условий за счет объединения узлов.\n  2. Сохраняет частичные соответствия между фактами при слиянии разных типов фактов. Это позволяет избежать полного вычисления (re-evaluation) всех фактов при любом изменении в рабочей памяти продукционной системы. Система работает только с самими изменениями (deltas).\n 3. Позволяет эффективно высвобождать память при удалении фактов.\n\n\n\nАлгоритм Rete широко используется для реализации сопоставления с образцом в системах с циклом сопоставление-решение-действие (match-resolve-act) для генерации и логического вывода.\n\n\n\nRete это Направленный ациклический граф из правил высшего порядка. Обычно это сеть объектов в оперативной памяти, устанавливливающая связь условий правил и фактов (реляционных кортежей). Сеть Rete действует как процессор реляционных запросов, выполняя проекции, выборки и мультиплицирование небольшого числа записей."
              }
            }
          ]
        }
      ]
    },
    {
      "data": {
        "title": "Искусственный интеллект",
        "description": ""
      },
      "children": [
        {
          "data": {
            "title": "Робототехника",
            "description": ""
          },
          "children": [
            {
              "data": {
                "title": "Айзек Азимов",
                "description": "![enter image description here](https://upload.wikimedia.org/wikipedia/commons/3/34/Isaac.Asimov01.jpg)\n\nАйзек Азимов (Isaac Asimov, имя при рождении Исак Юдович Озимов; 2 января 1920 года, Петровичи, Шумячский район, Смоленская область, РСФСР — 6 апреля 1992 года, Нью-Йорк, США) — американский писатель-фантаст, популяризатор науки, биохимик. Автор около 500 книг, в основном художественных (прежде всего в жанре научной фантастики, но также и в других жанрах: фэнтези, детектив, юмор) и научно-популярных (в самых разных областях — от астрономии и генетики до истории и литературоведения). Многократный лауреат премий Хьюго и Небьюла. Некоторые термины из его произведений — robotics (роботехника, роботика), positronic (позитронный), psychohistory (психоистория, наука о поведении больших групп людей) — прочно вошли в английский и другие языки. В англо-американской литературной традиции Азимова вместе с Артуром Кларком и Робертом Хайнлайном относят к «Большой тройке» писателей-фантастов.\n\n\n\nТри закона роботехники в научной фантастике — обязательные правила поведения для роботов, впервые сформулированные Айзеком Азимовым в рассказе «Хоровод» (1942).\n\n\n\nЗаконы гласят:\n\n1. Робот не может причинить вред человеку или своим бездействием допустить, чтобы человеку был причинён вред.\n2. Робот должен повиноваться всем приказам, которые даёт человек, кроме тех случаев, когда эти приказы противоречат Первому Закону.\n3. Робот должен заботиться о своей безопасности в той мере, в которой это не противоречит Первому или Второму Законам."
              }
            }
          ]
        }
      ]
    },
    {
      "data": {
        "title": "Программирование",
        "description": ""
      },
      "children": []
    },
    {
      "data": {
        "title": "Прикладная информатика",
        "description": ""
      },
      "children": [
        {
          "data": {
            "title": "АСНИ",
            "description": ""
          },
          "children": []
        },
        {
          "data": {
            "title": "САПР",
            "description": ""
          },
          "children": []
        }
      ]
    },
    {
      "data": {
        "title": "Вычислительная техника",
        "description": ""
      },
      "children": [
        {
          "data": {
            "title": "",
            "description": ""
          }
        }
      ]
    }
  ]
}
